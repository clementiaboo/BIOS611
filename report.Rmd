---
title: 'BIOS 611 HW #10'
author: "Clement Li"
date: "10/28/2021"
output:
  html_document: default
  pdf_document: default
---
```{r}
library(tidyverse)
library(shiny)
library(ggplot2)
library(dplyr)
library(glmnet)
library(kableExtra)
library(leaps)
library(gridExtra)
```

### This dataset was originally collected by researchers at the University of Minho in Braga, Portugal; Paulo Cortez and Alice Silva of the University of Minho analyzed this specific data in an academic paper titled “Using Data Mining to Predict Secondary School Student Performance” published through EUROSIS [ISBN 978-9077381-39-7]. The data is a sample of high school students obtained through a survey of students taking Math and Portuguese language courses at two high schools in Portugal: Gabriel Pereira and Mousinho da Silveira. Each observation represents the survey response of a single student. There are 33 variables. To avoid issues like duplicate students and differences in grades due to overall course difficulty (Math vs Portuguese), this analysis will only focus on the data containing survey responses of students in the Portuguese language class. The Portuguese language class dataset is composed of 649 unique student survey responses. https://www.kaggle.com/uciml/student-alcohol-consumption


```{r}
studalc <- read.csv("https://raw.githubusercontent.com/clementiaboo/bios-611-project/main/studalc.csv") %>%
  mutate(Gedu = factor(Gedu, 
    levels = c("None", "Primary", "Middle", "Secondary", "Higher"),
    labels = c("Minimal", "Minimal", "Middle", 
               "Secondary", "Higher")), 
    freetime = factor(freetime, c("Very Low", "Low", "Medium", "High", "Very High")), 
    famrel = factor(famrel, c("Very Bad", "Bad", "Neutral", "Good", "Excellent")), 
    G4 = as.factor(G4))

set.seed(1)
test = sample(1:nrow(studalc), 100)

```


### I split the variables into four categories: response, behavioral, background, and educational. The response variables are G4 and G3. G4 is a binary variable we created based on the given variables G1 and G2, which are the grades for the first and second term; G4 is 1 if G2 is greater than or equal to G1 (indicating improvement from the first term grade) and 0 otherwise. G3 is a numeric variable representing the final grade of a student, given in points out of 20. G1 and G2, mentioned earlier, use the same units as G3.

```{r}
studalc %>%
  mutate(G4 = ifelse(G4 == 1, "Increased", "Decreased")) 

ggplot(data=studalc, aes(x = G1, y = G2, colour = G4)) + 
  geom_point(position = position_jitter(.3, .3)) + 
  geom_abline(aes(slope = 1, intercept = 0), linetype = "dashed", 
              colour = "grey", size = 2) + 
  ylim(-1, 20) + xlim(-1, 20)
```

```{r}
ui <- fluidPage(
  plotOutput("plot", brush = "plot_brush"),
  tableOutput("data")
)
server <- function(input, output, session) {
  output$plot <- renderPlot({
    ggplot(mtcars, aes(wt, mpg)) + geom_point()
  }, res = 96)
  
  output$data <- renderTable({
    brushedPoints(mtcars, input$plot_brush)
  })
}
```


My final project addresses the question: “which educational variables act as the best predictors for a student’s final grade?” I trained several different regression models, each using a different subset of variables and their two-way interactions. The models were first trained on the same 549 observation training set and compared on the basis of their performances on the 100 observation test set.


The first model I tested is the most basic linear model that simply uses each predictor in the regression; this model was named “full.” From this model, I applied two different variable selection methods: backward selection and best subsets. For the simple multiple regression model, both backward selection and best subsets resulted in the same model that we called “Best,” which uses schoolsup, studytime, failures, reason, firstgen as predictors. 


In addition, I accounted for two-way interactions and built models using a similar variable selection process. I first created Full2, which considers all predictors as well as all the two-way interaction terms. Then, I used backward selection and the best subsets methods; in this case, these resulted in two different models, which are labeled as “Back2” and “Best2.” 

I also trained lasso and ridge regression models using all the educational variables and their two-way interactions and chose the optimal lasso and ridge penalty parameters with 10-fold cross-validation.

```{r}
ShowSubsets=function(regout){
  z=summary(regout)
  q=as.data.frame(z$outmat)
  q$Rsq=round(z$rsq*100,2)
  q$adjRsq=round(z$adjr2*100,2)
  q$Cp=round(z$cp,2)
  return(q)
}



all = regsubsets(G3~schoolsup+famsup+paid+absences+studytime+failures+reason+firstgen, data=studalc[-test,], method="exhaustive")

best.lm = lm(G3~schoolsup+studytime+failures+reason+firstgen, 
             data = studalc[-test,])

full = lm(G3~schoolsup+famsup+paid+absences+studytime+
            failures+reason+firstgen, 
          data = studalc[-test,])

all2 = regsubsets(G3~(schoolsup+famsup+paid+absences+studytime+failures+reason+firstgen)^2, data = studalc, method = "forward")

best.lm2 = lm(G3~(studytime+failures+reason+schoolsup:studytime+schoolsup:failures+famsup:reason+absences:failures+studytime:reason), data = studalc[-test,])

full2 = lm(G3~(schoolsup+famsup+paid+absences+studytime+failures+reason+firstgen)^2, data=studalc[-test,])

best.step2 = step(full2, scale=(summary(full2)$sigma)^2, trace = FALSE, direction = "backward")

edu = model.matrix(~(schoolsup + famsup + paid + absences + studytime + failures + reason + firstgen)^2 - 1, studalc[-test,])

edu.test = model.matrix(~(schoolsup + famsup + paid + absences + studytime + failures + reason + firstgen)^2 - 1, studalc[test,])

G3 = model.matrix(~G3 - 1, studalc[-test,])


#use 10-fold CV to find best lambda for ridge and lasso
set.seed(5)
lasso = cv.glmnet(x = edu, y = G3, alpha = 1, nfolds = 10)

ridge = cv.glmnet(x = edu, y = G3, alpha = 0, nfolds = 10)

#get test RMSE for each model
G3.errors = numeric(7)
G3.errors[1] = sqrt(mean(studalc[test,"G3"] - 
                        predict(full, studalc[test,]))^2)
G3.errors[2] = sqrt(mean(studalc[test,"G3"] - 
                        predict(best.lm, studalc[test,]))^2)
G3.errors[3] = sqrt(mean(studalc[test,"G3"] - 
                        predict(full2, studalc[test,]))^2)
G3.errors[4] = sqrt(mean(studalc[test,"G3"] - 
                        predict(best.lm2, studalc[test,]))^2)
G3.errors[5] = sqrt(mean(studalc[test,"G3"] - 
                        predict(best.step2, studalc[test,]))^2)
G3.errors[6] = sqrt(mean(studalc[test,"G3"] - 
                        predict(lasso, edu.test))^2)
G3.errors[7] = sqrt(mean(studalc[test,"G3"] - 
                        predict(ridge, edu.test))^2)

q2.models = c("Full", "Best",
              "Full2", "Best2", "Back2", "Lasso", 
              "Ridge")

fills=c("Full","Best Subsets","Full","Best Subsets","Backward","Lasso","Ridge")

q2.errors = data.frame(model = q2.models, RMSE = G3.errors, fills) %>%
  mutate(model = factor(model, levels = c("Full2", "Full",
              "Back2", "Best", "Ridge", "Lasso", 
              "Best2")))

ggplot(q2.errors) + geom_col(aes(x = model, y = RMSE,fill=fills)) +
  scale_fill_discrete(name = "Model Technique", labels = c("Backward","Best Subsets","Full","Lasso","Ridge"))+
  xlab("Models") + ylab("Test RMSE") +coord_flip() + ggtitle("Model Comparisons by RMSE")
```

Once all the models were trained, I evaluated their performances on the test set using RMSE (root-mean-square error). Lasso and Best2 had the two lowest RMSE values, and their test performances were quite similar. The lasso regression model uses just 2 predictors: studytime and failures. Best2 uses several more predictors: studytime, failures, reason, studytime:schoolsup, failures:schoolsup, reason:famsup, studytime:reason, failures:absences. 

Though the Best2 model uses over triple the amount of predictors, the lasso regression model gives a very similar test performance, which leads us to suspect that those other variables are more “noise” than “signal.” 

In conclusion, the two variables most predictive of G3 (final grade) are studytime and failures. The plots below demonstrate the strength of the relationship between studytime and G3 as well as failures (number of previous classes failed) and G3.

```{r}
g1 = ggplot(studalc) + 
  geom_point(aes(x = studytime, y = G3, colour = G3), 
             position = position_jitter(0.25, 0.25)) + 
  scale_color_gradient(low="blue", high="orange") + 
  theme(legend.position = "none")

g2 = ggplot(studalc) + 
  geom_point(aes(x = failures, y = G3, colour = G3), 
             position = position_jitter(0.25, 0.25)) + 
  scale_color_gradient(low="blue", high="orange") + ylab("") + 
  theme(legend.position = "none")

grid.arrange(g1, g2, ncol = 2)
```

